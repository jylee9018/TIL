{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.8859, 0.0845],\n",
      "        [0.7934, 0.6985]])\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(x_ones)\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3655, 0.3819, 0.2583],\n",
      "        [0.4897, 0.1765, 0.4965]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (\n",
    "    2,\n",
    "    3,\n",
    ")\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0537, 0.5968, 0.7007, 0.0537],\n",
      "        [0.2062, 0.6846, 0.0307, 0.8990],\n",
      "        [0.2593, 0.8962, 0.4554, 0.3575]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(tensor)\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "t0 = torch.ones(3, 4, 5, 6)\n",
    "print(t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t•\ttorch.ones(shape)는 주어진 **shape(모양)**을 가지며, 모든 요소가 1인 텐서를 반환합니다.\n",
    "\t•\t여기서는 4차원 텐서를 생성합니다.\n",
    "\t•\t첫 번째 차원: 3 (예: 배치 크기 또는 데이터 그룹 수)\n",
    "\t•\t두 번째 차원: 4 (예: 채널 수)\n",
    "\t•\t세 번째 차원: 5 (예: 행 또는 높이)\n",
    "\t•\t네 번째 차원: 6 (예: 열 또는 너비)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=0)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the element-wise product\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor) \n",
      " tensor([[3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor.matmul(tensor) \\n {tensor.matmul(tensor)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9249, 0.9489, 0.8694],\n",
      "        [0.3373, 0.6180, 0.6967],\n",
      "        [0.6396, 0.7953, 0.7760]]) \n",
      "\n",
      "tensor([[5.9249, 5.9489, 5.8694],\n",
      "        [5.3373, 5.6180, 5.6967],\n",
      "        [5.6396, 5.7953, 5.7760]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.rand(3, 3)\n",
    "\n",
    "print(tensor1, \"\\n\")\n",
    "tensor1.add_(5)\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7623, 0.4414, 0.9000],\n",
      "        [0.1750, 0.6541, 0.2043],\n",
      "        [0.1432, 0.0069, 0.9604]]) \n",
      "\n",
      "tensor([[0.7623, 0.4414, 0.9000],\n",
      "        [0.1750, 0.6541, 0.2043],\n",
      "        [0.1432, 0.0069, 0.9604]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.rand(3, 3)\n",
    "\n",
    "print(tensor1, \"\\n\")\n",
    "tensor1.add(5)\n",
    "print(tensor1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
